{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23be8abf-2c79-4ebd-903e-e3d969bd6095",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook is for a pipeline of analyzing and visualizing a time-seires dataset. \n",
    "\n",
    "## Step 1: load package and preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c262e0-6306-4d1f-b37e-39e6da771d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from wav2sleep.data.edf import load_edf_data\n",
    "from wav2sleep.data.txt import parse_txt_annotations\n",
    "from wav2sleep.data.utils import interpolate_index\n",
    "from wav2sleep.data.xml import parse_xml_annotations\n",
    "from wav2sleep.data.xml_parse_all import parse_all_annotations, annotate_waveform\n",
    "from wav2sleep.data.rpoints import parse_process_rpoints_annotations\n",
    "from wav2sleep.settings import *\n",
    "from wav2sleep.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd29ea5-2105-42ab-9a10-ed583212ebbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        channel          sfreq_hz  phys_unit lowpass highpass\n",
      "0            C3    [128.0, 128.0]        107       —        —\n",
      "1            C4    [128.0, 128.0]        107       —        —\n",
      "2            A1    [128.0, 128.0]        107       —        —\n",
      "3            A2    [128.0, 128.0]        107       —        —\n",
      "4           LOC    [128.0, 128.0]        107       —        —\n",
      "5           ROC    [128.0, 128.0]        107       —        —\n",
      "6          ECG2    [256.0, 256.0]        107       —        —\n",
      "7          ECG1    [256.0, 256.0]        107       —        —\n",
      "8          EMG1    [256.0, 256.0]        107       —        —\n",
      "9          EMG2    [256.0, 256.0]        107       —        —\n",
      "10         EMG3    [256.0, 256.0]        107       —        —\n",
      "11        L Leg      [64.0, 64.0]        107       —        —\n",
      "12        R Leg      [64.0, 64.0]        107       —        —\n",
      "13      AIRFLOW      [32.0, 32.0]        107       —        —\n",
      "14  THOR EFFORT      [32.0, 32.0]        107       —        —\n",
      "15  ABDO EFFORT      [32.0, 32.0]        107       —        —\n",
      "16        SNORE    [256.0, 256.0]        107       —        —\n",
      "17          SUM      [32.0, 32.0]        107       —        —\n",
      "18     POSITION        [1.0, 1.0]        107       —        —\n",
      "19    OX STATUS        [1.0, 1.0]        107       —        —\n",
      "20        PULSE        [1.0, 1.0]        107       —        —\n",
      "21         SpO2        [1.0, 1.0]        107       —        —\n",
      "22   NASAL PRES      [64.0, 64.0]        107       —        —\n",
      "23      PlethWV    [128.0, 128.0]        107       —        —\n",
      "24        Light  [1024.0, 1024.0]        107       —        —\n",
      "25        HRate  [1024.0, 1024.0]        107       —        —\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import mne, pandas as pd, pathlib\n",
    "### please modify path here\n",
    "# annotation_path = '/scratch/besp/shared_data/shhs/polysomnography/annotations-events-nsrr/shhs1/shhs1-201935-nsrr.xml'\n",
    "# edf_path = '/scratch/besp/shared_data/shhs/polysomnography/edfs/shhs1/shhs1-201935.edf'\n",
    "# DATA_FOR_CHECK = 'shhs'\n",
    "annotation_path = '/scratch/besp/shared_data/ccshs/polysomnography/annotations-events-nsrr/ccshs-trec-1800823-nsrr.xml'\n",
    "edf_path = '/scratch/besp/shared_data/ccshs/polysomnography/edfs/ccshs-trec-1800823.edf'\n",
    "# annotation_path = '/scratch/besp/shared_data/ccshs/polysomnography/annotations-events-nsrr/ccshs-trec-1800248-nsrr.xml'\n",
    "# edf_path = '/scratch/besp/shared_data/ccshs/polysomnography/edfs/ccshs-trec-1800248.edf'\n",
    "DATA_FOR_CHECK = 'ccshs'\n",
    "\n",
    "\n",
    "###########################\n",
    "edf = pathlib.Path(edf_path)\n",
    "raw = mne.io.read_raw_edf(edf, preload=False, verbose=\"error\")\n",
    "\n",
    "\n",
    "hdr          = raw._raw_extras[0]              \n",
    "rec_len_sec  = hdr['record_length']           \n",
    "n_samps_list = hdr['n_samps']                  \n",
    "\n",
    "rows = []\n",
    "for idx, ch in enumerate(raw.info['chs']):\n",
    "    sfreq = n_samps_list[idx] / rec_len_sec    \n",
    "    rows.append(dict(channel   = ch['ch_name'],\n",
    "                     sfreq_hz  = sfreq,\n",
    "                     phys_unit = ch.get('unit', '—'),\n",
    "                     lowpass   = ch.get('lowpass',  '—'),\n",
    "                     highpass  = ch.get('highpass', '—')))\n",
    "\n",
    "df = pd.DataFrame(rows)#.sort_values(\"sfreq_hz\", ascending=False)\n",
    "print(df)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8260817-5498-4614-8635-e92e4a98e396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocessing notes:\n",
    "1. select a time window: here we use 10h \n",
    "2. select different frequency for different channel\n",
    "3. resample using interpolate\n",
    "4. channel-wise normalization\n",
    "'''\n",
    "def _mne_lowpass_series(s: pd.Series, fs,\n",
    "                        cutoff=None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Apply low-pass filter to a pd.Series using MNE.\n",
    "    Keeps frequencies below the cutoff.\n",
    "    \n",
    "    Parameters:\n",
    "    - s: input signal\n",
    "    - fs: sampling rate\n",
    "    - cutoff: cutoff frequency (Hz)\n",
    "    \"\"\"\n",
    "    if cutoff is None:\n",
    "        return s\n",
    "\n",
    "    x = s.to_numpy(np.float64)[np.newaxis, :]  # shape (1, n)\n",
    "\n",
    "    x_filt = mne.filter.filter_data(\n",
    "        x, sfreq=fs,\n",
    "        l_freq=None, h_freq=cutoff, \n",
    "        method='fir', phase='zero-double',\n",
    "        n_jobs='cuda',\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    return pd.Series(x_filt, index=s.index, name=s.name)\n",
    "\n",
    "def process_edf(edf: pd.DataFrame):\n",
    "    \"\"\"Process dataframe of EDF data.\"\"\"\n",
    "    signals = []\n",
    "\n",
    "    def _process_edf_column(col, target_index, preprocessed_fs):\n",
    "        \"\"\"Process signal column of EDF\"\"\"\n",
    "        if col in edf:\n",
    "            \n",
    "            raw = edf[col].dropna()\n",
    "            \n",
    "            # print(len(raw.loc[0:1]))\n",
    "            raw_fs = len(raw.loc[0:1]) - 1\n",
    "            \n",
    "            if raw_fs > preprocessed_fs: \n",
    "                raw_hp = _mne_lowpass_series(raw, raw_fs, cutoff = preprocessed_fs/2)\n",
    "            else:\n",
    "                raw_hp = raw\n",
    "            \n",
    "            resampled = interpolate_index(raw_hp, target_index,\n",
    "                              method=\"linear\", squeeze=False)\n",
    "            # normalized_wav = (resampled_wav - resampled_wav.mean()) / resampled_wav.std()\n",
    "            print(\"col:\", col, \"length:\", resampled.shape)\n",
    "            signals.append(resampled)\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    _process_edf_column(ECG, ECG_SIGNAL_INDEX, FREQ_ECG)\n",
    "    _process_edf_column(HR, HR_SIGNAL_INDEX, FREQ_HR)\n",
    "\n",
    "    _process_edf_column(SPO2, SPO2_SIGNAL_INDEX, FREQ_SPO2)\n",
    "    _process_edf_column(OX, OX_SIGNAL_INDEX, FREQ_OX)\n",
    "    _process_edf_column(ABD, ABD_SIGNAL_INDEX, FREQ_ABD)\n",
    "    _process_edf_column(THX, THX_SIGNAL_INDEX, FREQ_THX)\n",
    "    _process_edf_column(AF, AF_SIGNAL_INDEX, FREQ_AF)\n",
    "    _process_edf_column(NP, NP_SIGNAL_INDEX, FREQ_NP)\n",
    "    _process_edf_column(SN, SN_SIGNAL_INDEX, FREQ_SN)\n",
    "    \n",
    "    _process_edf_column(EMG_LLeg, EMG_LLeg_SIGNAL_INDEX, FREQ_EMG_LLeg)\n",
    "    _process_edf_column(EMG_RLeg, EMG_RLeg_SIGNAL_INDEX, FREQ_EMG_RLeg)\n",
    "    _process_edf_column(EMG_LChin, EMG_LChin_SIGNAL_INDEX, FREQ_EMG_LChin)\n",
    "    _process_edf_column(EMG_RChin, EMG_RChin_SIGNAL_INDEX, FREQ_EMG_RChin)\n",
    "    _process_edf_column(EMG_CChin, EMG_CChin_SIGNAL_INDEX, FREQ_EMG_CChin)\n",
    "    _process_edf_column(EOG_L, EOG_L_SIGNAL_INDEX, FREQ_EOG_L)\n",
    "    _process_edf_column(EOG_R, EOG_R_SIGNAL_INDEX, FREQ_EOG_R)\n",
    "    \n",
    "    is_na_C3 = _process_edf_column(EEG_C3, EEG_C3_SIGNAL_INDEX, FREQ_EEG_C3)\n",
    "    is_na_C4 = _process_edf_column(EEG_C4, EEG_C4_SIGNAL_INDEX, FREQ_EEG_C4)\n",
    "    is_na_A1 = _process_edf_column(EEG_A1, EEG_A1_SIGNAL_INDEX, FREQ_EEG_A1)\n",
    "    is_na_A2 = _process_edf_column(EEG_A2, EEG_A2_SIGNAL_INDEX, FREQ_EEG_A2)\n",
    "    is_na_O1 = _process_edf_column(EEG_O1, EEG_O1_SIGNAL_INDEX, FREQ_EEG_O1)\n",
    "    is_na_O2 = _process_edf_column(EEG_O2, EEG_O2_SIGNAL_INDEX, FREQ_EEG_O2)\n",
    "    is_na_F3 = _process_edf_column(EEG_F3, EEG_F3_SIGNAL_INDEX, FREQ_EEG_F3)\n",
    "    is_na_F4 = _process_edf_column(EEG_F4, EEG_F4_SIGNAL_INDEX, FREQ_EEG_F4)\n",
    "    \n",
    "    # add a logic to check\n",
    "    \n",
    "    is_na_C3_A2 = _process_edf_column(EEG_C3_A2, EEG_C3_A2_SIGNAL_INDEX, FREQ_EEG_C3_A2)\n",
    "    is_na_C4_A1 = _process_edf_column(EEG_C4_A1, EEG_C4_A1_SIGNAL_INDEX, FREQ_EEG_C4_A1)\n",
    "    is_na_F3_A2 = _process_edf_column(EEG_F3_A2, EEG_F3_A2_SIGNAL_INDEX, FREQ_EEG_F3_A2)\n",
    "    is_na_F4_A1 = _process_edf_column(EEG_F4_A1, EEG_F4_A1_SIGNAL_INDEX, FREQ_EEG_F4_A1)\n",
    "    is_na_O1_A2 = _process_edf_column(EEG_O1_A2, EEG_O1_A2_SIGNAL_INDEX, FREQ_EEG_O1_A2)\n",
    "    is_na_O2_A1 = _process_edf_column(EEG_O2_A1, EEG_O2_A1_SIGNAL_INDEX, FREQ_EEG_O2_A1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    merged_df = pd.concat(signals, axis=1).astype(np.float32)\n",
    "    \n",
    "    if (EEG_C3_A2 not in merged_df.columns.to_list()) and (is_na_C3 == 0) and (is_na_A2 == 0):\n",
    "        merged_df[EEG_C3_A2] = merged_df[EEG_C3] - merged_df[EEG_A2]\n",
    "    if (EEG_C4_A1 not in merged_df.columns.to_list()) and (is_na_C4 == 0) and (is_na_A1 == 0):\n",
    "        merged_df[EEG_C4_A1] = merged_df[EEG_C4] - merged_df[EEG_A1]\n",
    "    if (EEG_F3_A2 not in merged_df.columns.to_list()) and (is_na_F3 == 0) and (is_na_A2 == 0):\n",
    "        merged_df[EEG_F3_A2] = merged_df[EEG_F3] - merged_df[EEG_A2]\n",
    "    if (EEG_F4_A1 not in merged_df.columns.to_list()) and (is_na_F4 == 0) and (is_na_A1 == 0):\n",
    "        merged_df[EEG_F4_A1] = merged_df[EEG_F4] - merged_df[EEG_A1]\n",
    "    if (EEG_O1_A2 not in merged_df.columns.to_list()) and (is_na_O1 == 0) and (is_na_A2 == 0):\n",
    "        merged_df[EEG_O1_A2] = merged_df[EEG_O1] - merged_df[EEG_A2]\n",
    "    if (EEG_O2_A1 not in merged_df.columns.to_list()) and (is_na_O2 == 0) and (is_na_A1 == 0):\n",
    "        merged_df[EEG_O2_A1] = merged_df[EEG_O2] - merged_df[EEG_A1]    \n",
    "    \n",
    "    merged_df = (merged_df - merged_df.mean()) / merged_df.std()\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\n",
    "def process(edf_fp: str, label_fp: str, output_fp: str, overwrite: bool = False) -> bool:\n",
    "    \"\"\"Process night of data.\"\"\"\n",
    "    if os.path.exists(output_fp) and not overwrite:\n",
    "        logger.debug(f'Skipping {edf_fp=}, {output_fp=}, already exists')\n",
    "        return False\n",
    "    else:\n",
    "        os.makedirs(os.path.dirname(output_fp), exist_ok=True)\n",
    "        \n",
    "    # Process labels\n",
    "    if label_fp.endswith('.xml'):\n",
    "        try:\n",
    "            labels = parse_xml_annotations(label_fp) # parse sleep stages\n",
    "            all_df = parse_all_annotations(label_fp) # parse all other events (arousals, respiratory)\n",
    "        except Exception as e:\n",
    "            logger.error(f'Failed to parse: {label_fp}.')\n",
    "            logger.error(e)\n",
    "            return False\n",
    "    else:\n",
    "        labels = parse_txt_annotations(fp=label_fp)\n",
    "        # NOTE: If we end up using a dataset with txt annotations, we will want to write another function to parse all other events\n",
    "        if labels is None:\n",
    "            logger.error(f'Failed to parse: {label_fp}.')\n",
    "            return False\n",
    "    labels = labels.reindex(TARGET_LABEL_INDEX).fillna(-1) # these are sleep stage labels\n",
    "    # Check for N1, N3 or REM presence. (Recordings with just sleep-wake typically use N2 as sole sleep class)\n",
    "    stage_counts = labels.value_counts()\n",
    "    if stage_counts.get(1.0) is None and stage_counts.get(3.0) is None and stage_counts.get(4.0) is None: \n",
    "        logger.error(f'No N1, N3 or REM in {label_fp}.')\n",
    "        output_fp = output_fp.replace('.parquet', 'sleepstage.issues.parquet') # note these are still useful since sleep stages are not strictly necessary for captions\n",
    "    \n",
    "    edf = load_edf_data(edf_fp, columns=EDF_COLS, raise_on_missing=False)\n",
    "    waveform_df = process_edf(edf)\n",
    "    output_df = pd.concat([waveform_df, labels], axis=1)\n",
    "    \n",
    "    \n",
    "    # output_df = annotate_waveform(output_df, [all_df])\n",
    "    \n",
    "    # output_df.to_parquet(output_fp)\n",
    "    return output_df, all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddb44a47-6f80-4bd2-b282-8025db69db3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: ECG length: (3686400, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: HR length: (28800, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: SPO2 length: (28800, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: OX length: (28800, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: ABD length: (230400, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: THX length: (230400, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: AF length: (230400, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: NP length: (230400, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: SN length: (921600, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EMG_LLeg length: (1843200, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EMG_RLeg length: (1843200, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EMG_LChin length: (1843200, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EMG_RChin length: (1843200, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EMG_CChin length: (1843200, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EOG_L length: (1843200, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EOG_R length: (1843200, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EEG_C3 length: (1843200, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EEG_C4 length: (1843200, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EEG_A1 length: (1843200, 1)\n",
      "<class 'pandas.core.indexes.numeric.Float64Index'> <class 'pandas.core.indexes.numeric.Float64Index'>\n",
      "col: EEG_A2 length: (1843200, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_path = f'./test/test_{DATA_FOR_CHECK}/test.parquet'\n",
    "output_df, all_df = process(edf_path, annotation_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8999ed9e-ddf4-40ee-9824-ab2e1c7b338c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Types</th>\n",
       "      <th>Concepts</th>\n",
       "      <th>Starts</th>\n",
       "      <th>Ends</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Limb Movement</td>\n",
       "      <td>Limb movement</td>\n",
       "      <td>42.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>R Leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Limb Movement</td>\n",
       "      <td>Limb movement</td>\n",
       "      <td>61.4</td>\n",
       "      <td>62.2</td>\n",
       "      <td>R Leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Limb Movement</td>\n",
       "      <td>Limb movement</td>\n",
       "      <td>94.2</td>\n",
       "      <td>96.0</td>\n",
       "      <td>R Leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Limb Movement</td>\n",
       "      <td>Limb movement</td>\n",
       "      <td>110.8</td>\n",
       "      <td>114.7</td>\n",
       "      <td>L Leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Limb Movement</td>\n",
       "      <td>Limb movement</td>\n",
       "      <td>116.7</td>\n",
       "      <td>118.9</td>\n",
       "      <td>R Leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>Limb Movement</td>\n",
       "      <td>Limb movement</td>\n",
       "      <td>41180.8</td>\n",
       "      <td>41181.3</td>\n",
       "      <td>R Leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>Limb Movement</td>\n",
       "      <td>Limb movement</td>\n",
       "      <td>41185.2</td>\n",
       "      <td>41186.1</td>\n",
       "      <td>R Leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>SpO2 artifact</td>\n",
       "      <td>41192.8</td>\n",
       "      <td>41236.0</td>\n",
       "      <td>SpO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>Limb Movement</td>\n",
       "      <td>Limb movement</td>\n",
       "      <td>41199.6</td>\n",
       "      <td>41200.5</td>\n",
       "      <td>L Leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>Limb Movement</td>\n",
       "      <td>Limb movement</td>\n",
       "      <td>41203.5</td>\n",
       "      <td>41204.2</td>\n",
       "      <td>L Leg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1357 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Types        Concepts   Starts     Ends Signal\n",
       "0     Limb Movement  Limb movement      42.5     47.0  R Leg\n",
       "1     Limb Movement  Limb movement      61.4     62.2  R Leg\n",
       "2     Limb Movement  Limb movement      94.2     96.0  R Leg\n",
       "3     Limb Movement  Limb movement     110.8    114.7  L Leg\n",
       "4     Limb Movement  Limb movement     116.7    118.9  R Leg\n",
       "...             ...             ...      ...      ...    ...\n",
       "1352  Limb Movement  Limb movement   41180.8  41181.3  R Leg\n",
       "1353  Limb Movement  Limb movement   41185.2  41186.1  R Leg\n",
       "1354    Respiratory   SpO2 artifact  41192.8  41236.0   SpO2\n",
       "1355  Limb Movement  Limb movement   41199.6  41200.5  L Leg\n",
       "1356  Limb Movement  Limb movement   41203.5  41204.2  L Leg\n",
       "\n",
       "[1357 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e68740-a4ea-4199-9d2b-51a93d729f0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Sanity Check for the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e15bce-6b52-496f-834d-774cfa61dedd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff33f0d-a4a9-43ad-88c4-9e6a5e4926de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437109b-338e-43e9-96e7-e634f6138e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pd.isna(df['EMG_LLeg_events']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b3fa9-223e-444f-b6d4-c92303c6bbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "\n",
    "df_clean = df.dropna(how=\"all\") \n",
    "\n",
    "print(len(df_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee83d1-eac1-4b36-a985-02b23526f506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b05781-fd2b-4e4c-80f4-d1ec8bd94e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['ECG'])\n",
    "print(df['ECG'].dropna())\n",
    "print(df.columns)\n",
    "print(df['SPO2_events'].unique())\n",
    "print(df['Stage'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e9f49-6ed3-437a-a11b-88a76987b188",
   "metadata": {},
   "source": [
    "## Step 3: Check Each Channel in the Time Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124ba49-eada-4957-ac2c-cab6b008752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "def format_overlapping_events(events_df, event_cols):\n",
    "    # Create a new column for overlapping events\n",
    "    events_df['Multiple Events'] = None\n",
    "\n",
    "    # For each row, check for overlapping events\n",
    "    for idx in events_df.index:\n",
    "        row_events = []\n",
    "        for col in event_cols:\n",
    "            if pd.notna(events_df.loc[idx, col]):\n",
    "                row_events.append(events_df.loc[idx, col])\n",
    "        \n",
    "        # If multiple events, combine them and set original columns to NaN\n",
    "        if len(row_events) > 1:\n",
    "            events_df.loc[idx, 'Multiple Events'] = ' and '.join(row_events)\n",
    "            for col in event_cols:\n",
    "                events_df.loc[idx, col] = None\n",
    "\n",
    "    # Add overlapping_events to event_cols\n",
    "    event_cols.append('Multiple Events')\n",
    "\n",
    "    return events_df, event_cols\n",
    "\n",
    "def get_colormap(events_df, event_cols):\n",
    "    custom_colors = [\n",
    "        '#800000',  # Maroon (Dark Red)\n",
    "        '#457B9D',  # Steel Blue\n",
    "        '#556B2F',  # Dark Olive Green\n",
    "        '#533100',  # Brown\n",
    "        '#581845',  # Dark Purple\n",
    "        '#2F4F4F',  # Dark Slate Gray'\n",
    "        '#CD5C5C',  # Indian Red (a bit lighter, but distinct)\n",
    "        '#DAA520',  # Goldenrod\n",
    "        '#40E0D0',  # Turquoise\n",
    "    ]\n",
    "    all_events = []\n",
    "    for col in event_cols:\n",
    "        all_events.extend(events_df[col].dropna().unique())\n",
    "    unique_events = np.unique(all_events)\n",
    "    event_colors = dict(zip(unique_events, custom_colors[:len(unique_events)]))\n",
    "    return event_colors\n",
    "def plot_channels_annotations_sleep_stage(df_input, channel_cols, stage_col = 'Sleep Stage', stage_labels=None):\n",
    "    \"\"\"\n",
    "    Plot multiple channels of sensor data with highlighted event intervals. NOTE: sleep stage should be bfilled to propagate 30-sec epoch stage to all timepoints in the interval\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_input : pandas.DataFrame\n",
    "        DataFrame containing the data with channel and channel_events annotation columns\n",
    "    channel_cols : list\n",
    "        List of channel column names to plot. Assumes annotation columns with _events exists for some channels.\n",
    "    stage_col : str \n",
    "        Name of sleep stage column\n",
    "    \"\"\"\n",
    "\n",
    "    n_channels = len(channel_cols)\n",
    "    fig, axes = plt.subplots(n_channels, 1, figsize=(18, 5*n_channels), sharex=True)\n",
    "\n",
    "    # First plot the event annotation boxes that will span all subplots\n",
    "    event_cols = [col for col in df_input.columns if col.endswith('_events')]\n",
    "    # Create a copy of df with just event columns\n",
    "    events_df = df_input[event_cols].copy()\n",
    "    # Create copy of df, might manipulate \n",
    "    df = df_input.copy()\n",
    "\n",
    "    # Format overlapping events in a new column 'Multiple Events'\n",
    "    events_df, event_cols = format_overlapping_events(events_df, event_cols)\n",
    "\n",
    "    # Create a color map for all unique events across all columns\n",
    "    event_colors = get_colormap(events_df, event_cols)\n",
    "\n",
    "    # --- Plot annotation events\n",
    "    for event_col in event_cols:\n",
    "        # Get unique events in this window\n",
    "        events = events_df[event_col].dropna().unique()\n",
    "        for event in events:\n",
    "            # Find start and end times for each event\n",
    "            event_mask = events_df[event_col] == event\n",
    "            event_starts = events_df.index[event_mask & ~event_mask.shift(1).fillna(False)]\n",
    "            event_ends = events_df.index[event_mask & ~event_mask.shift(-1).fillna(False)]\n",
    "            \n",
    "            # Add transparent box for each event occurrence spanning all subplots\n",
    "            for start_time, end_time in zip(event_starts, event_ends):\n",
    "                # Add to first subplot to avoid duplicate legend entries+_\n",
    "                span = axes[0].axvspan(start_time, end_time, color=event_colors[event], alpha=0.3, label=f'{event_col}: {event}')\n",
    "                # Add same span to all other subplots without labels\n",
    "                for ax in axes[1:]:\n",
    "                    ax.axvspan(start_time, end_time, color=event_colors[event], alpha=0.3)\n",
    "\n",
    "    # --- Plot each channel in its own subplot\n",
    "    for idx, (channel, ax) in enumerate(zip(channel_cols, axes)):\n",
    "        if channel in df.columns:\n",
    "            # Plot non-NaN values only\n",
    "            valid_data = df[channel].dropna()\n",
    "            if not valid_data.empty:\n",
    "                ax.plot(valid_data.index, valid_data.values, linewidth=0.5)\n",
    "                ax.set_ylabel(channel)\n",
    "                # Add grid\n",
    "                #ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                ax.set_xlabel('Time (seconds)')\n",
    "                ax.tick_params(axis='x', labelbottom=True)\n",
    "\n",
    "    # --- get handles and labels ready to plot legend of annotation events\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    if handles:\n",
    "        # Get unique handles and labels while preserving order\n",
    "        unique_labels = []\n",
    "        unique_handles = []\n",
    "        for h, l in zip(handles, labels):\n",
    "            if l not in unique_labels:\n",
    "                unique_labels.append(l)\n",
    "                unique_handles.append(h)\n",
    "\n",
    "    # --- Sleep Stages\n",
    "    # Optional: define readable labels\n",
    "    if stage_labels is None:\n",
    "        # Get unique sleep stages\n",
    "        unique_stages = df[stage_col].dropna().unique()\n",
    "        stage_labels = {int(k): 'Stage' + str(int(k)) for k in unique_stages}\n",
    "    else:\n",
    "        # map sleep stage numbers to labels \n",
    "        df[stage_col] = df[stage_col].map(stage_labels)\n",
    "        # Get unique sleep stages\n",
    "        unique_stages = df[stage_col].dropna().unique()\n",
    "    # Overlay sleep stage bar at bottom of every axis (use height just below lowest frequency)\n",
    "    stage_band_y_axes = {}\n",
    "    band_height_axes = {}\n",
    "    for i, ax in enumerate(axes):\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        stage_band_y_axes[i] = ymin - ((ymax-ymin) * 0.05)  # slight offset below\n",
    "        band_height_axes[i] = ((ymax-ymin) * 0.05)\n",
    "    # Custom color map\n",
    "    color_map = ListedColormap(plt.cm.tab10.colors[:len(unique_stages)])\n",
    "    stage_to_idx = {stage: idx for idx, stage in enumerate(unique_stages)} # map stage number to index number to use to access color_map\n",
    "    # Construct colored rectangles (one per time bin)\n",
    "    for j, (channel, ax) in enumerate(zip(channel_cols, axes)):\n",
    "        df_subset = df[[channel, stage_col]].dropna()\n",
    "        stage_values = df_subset[stage_col].values\n",
    "        time_values = df_subset.index.values\n",
    "        # Detect stage changes\n",
    "        changes = np.where(stage_values[:-1] != stage_values[1:])[0] + 1 # indices where stage changes\n",
    "        segments = np.split(np.arange(len(stage_values)), changes) # split into segments of continuous sleep stages\n",
    "        # Draw one rectangle per segment\n",
    "        for seg in segments:\n",
    "            stage = stage_values[seg[0]]\n",
    "            ax.add_patch(plt.Rectangle(\n",
    "                (time_values[seg[0]], stage_band_y_axes[j]), # anchor\n",
    "                time_values[seg[-1]] - time_values[seg[0]], # width\n",
    "                band_height_axes[j], # height\n",
    "                color=color_map(stage_to_idx[stage]),\n",
    "                linewidth=0\n",
    "            ))\n",
    "\n",
    "    # --- Legend for sleep stages\n",
    "    legend_patches = [plt.Line2D([0], [0], color=color_map(stage_to_idx[stage]), lw=6)\n",
    "                      for stage in unique_stages] # dummy lines for legend\n",
    "    #legend_labels = [stage_labels[int(stage)] for stage in unique_stages]\n",
    "    legend_labels = unique_stages\n",
    "    for j, ax in enumerate(axes):\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        legend1 = ax.legend(legend_patches, legend_labels, loc='center left', bbox_to_anchor=(1.0, 0.5),\n",
    "                title=\"Sleep Stage\", fontsize='small')\n",
    "        ax.add_artist(legend1) # add first legend as artist\n",
    "        ax.set_ylim(stage_band_y_axes[j], ymax)\n",
    "    \n",
    "    # --- Legend for annotation events\n",
    "    if handles:\n",
    "        for ax in axes:\n",
    "            ax.legend(unique_handles, unique_labels, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b7070-d68f-4727-86d8-d4f03cf92c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "# df['Sleep Stage'] = 1 # just make a column\n",
    "\n",
    "# real_COLS = df.columns.to_list()\n",
    "# real_COLS.remove('Stage')\n",
    "\n",
    "real_COLS = ['ECG', 'HR', 'SPO2', 'OX', 'ABD', 'THX', 'AF', 'NP', 'SN', 'EMG_LLeg',\n",
    "       'EMG_RLeg', 'EMG_LChin', 'EMG_RChin', 'EMG_CChin', 'EOG_L', 'EOG_R']\n",
    "print(real_COLS)\n",
    "#####################################\n",
    "\n",
    "stage_labels={\n",
    "    0: 'Awake', \n",
    "    1: 'Light Sleep', \n",
    "    2: 'Light Sleep', \n",
    "    3: 'Deep Sleep', \n",
    "    4: 'REM'\n",
    "}\n",
    "SPO2_labels={\n",
    "    'SpO2 artifact': 'SpO2 artifact', \n",
    "    'SpO2 desaturation': 'SpO2 desaturation'\n",
    "}\n",
    "\n",
    "df['Stage'] = df['Stage'].bfill()\n",
    "df['SPO2_events'] = df['SPO2_events'].bfill()\n",
    "\n",
    "df_show = df[100:140]\n",
    "# might want to subset df to a smaller window here\n",
    "fig = plot_channels_annotations_sleep_stage(df_show, real_COLS, 'Stage', stage_labels)\n",
    "# fig = plot_channels_annotations_sleep_stage(df_show, real_COLS, 'SPO2_events', SPO2_labels)\n",
    "\n",
    "plt.show()\n",
    "# EDF_COLS are the channel column names you want to plot \n",
    "# 'Sleep Stage' is the name of the sleep stage column\n",
    "# stage_labels is the dict I sent you above, grouping stages as awake, light sleep, deep sleep, or REM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70efd5d-ae75-4c9d-86fb-93e0f90fe120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd24662-d8c1-4edb-841c-e4c6f38da0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv]",
   "language": "python",
   "name": "conda-env-.conda-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b11727-8db5-4bc1-b8a2-cdd1ad1a19bb",
   "metadata": {},
   "source": [
    "## Step 1: check the CLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c7e6f4-31b4-4b5b-9e16-532788add11c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from melp.models.uniclip_model import UniCLIPModel          \n",
    "\n",
    "\n",
    "import os, torch.distributed as dist\n",
    "if not dist.is_initialized():\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"29500\"   \n",
    "    dist.init_process_group(backend=\"gloo\", rank=0, world_size=1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "BATCH = 4                     \n",
    "C, FREQ, WIN = 2, 128, 30     \n",
    "T = FREQ * WIN                \n",
    "\n",
    "\n",
    "dummy_ecg    = torch.zeros(BATCH, C, T)      # (B, C, T)\n",
    "dummy_report = [\"This is a demo report.\"] * BATCH\n",
    "\n",
    "batch = {\"psg\": dummy_ecg}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddbba211-8a6d-4025-9719-99d798c2e4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrastive loss = 1.3862943649291992\n"
     ]
    }
   ],
   "source": [
    "model = UniCLIPModel(psg_encoder_name=\"resnet18\",\n",
    "                  text_encoder_name=\"google/flan-t5-base\").eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss_dict, _ = model.shared_step(batch, batch_idx=0)\n",
    "print(\"contrastive loss =\", loss_dict[\"loss\"].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4148ea-db68-4426-a505-d0c8e9e24c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CLIPModel()\n",
    "model.train()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.2)\n",
    "\n",
    "opt.zero_grad(set_to_none=True)\n",
    "loss_dict, _ = model.shared_step(batch, batch_idx=0)\n",
    "loss_dict[\"loss\"].backward()\n",
    "opt.step()\n",
    "\n",
    "print(\"after one step, logit_scale =\", model.logit_scale.exp().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a6c93e-db4a-46f2-aa3a-370af19808e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity matrix:\n",
      " tensor([[1.2841, 1.2841, 1.2841, 1.2841],\n",
      "        [1.2841, 1.2841, 1.2841, 1.2841],\n",
      "        [1.2841, 1.2841, 1.2841, 1.2841],\n",
      "        [1.2841, 1.2841, 1.2841, 1.2841]])\n"
     ]
    }
   ],
   "source": [
    "model = CLIPModel().eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    psg_emb = model.encoders[\"all\"](batch[\"ecg\"])              # (B, 256)\n",
    "    tok     = model._tokenize(batch[\"report\"])\n",
    "    txt_emb = model.encode_text(tok[\"input_ids\"], tok[\"attention_mask\"])[\"proj_text_emb\"]  # (B, 256)\n",
    "\n",
    "\n",
    "    psg_emb = torch.nn.functional.normalize(psg_emb, dim=-1)\n",
    "    txt_emb = torch.nn.functional.normalize(txt_emb, dim=-1)\n",
    "    sim = (psg_emb @ txt_emb.t()) * model.logit_scale.exp()    # (B, B)\n",
    "\n",
    "print(\"similarity matrix:\\n\", sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ddc376-002d-48c0-b69a-d55f9ebe6ba9",
   "metadata": {},
   "source": [
    "## Step 2: Check MAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40835fcf-3607-4adb-9c53-ebdac3a25ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from melp.models.mae_model import MAEModel          \n",
    "\n",
    "\n",
    "import os, torch.distributed as dist\n",
    "if not dist.is_initialized():\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"29500\"   \n",
    "    dist.init_process_group(backend=\"gloo\", rank=0, world_size=1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "BATCH = 4                     \n",
    "C, FREQ, WIN = 21, 64, 30     \n",
    "T = FREQ * WIN                \n",
    "\n",
    "\n",
    "dummy_ecg    = torch.zeros(BATCH, C, T)      # (B, C, T)\n",
    "dummy_report = [\"This is a demo report.\"] * BATCH\n",
    "\n",
    "batch = {\"ecg\": dummy_ecg, \"report\": dummy_report}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c9ef5b-5bd5-4a1a-bb24-d703a3c08ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters:\n",
      "| Module      | # params    |\n",
      "|-------------|-------------|\n",
      "| dec_blocks  | 12,609,536  |\n",
      "| dec_norm    | 1,024       |\n",
      "| dec_proj    | 131,584     |\n",
      "| encoders    | 5,625,472   |\n",
      "| lm_model    | 109,628,544 |\n",
      "| logit_scale | 1           |\n",
      "| mask_token  | 512         |\n",
      "| pos_dec     | 24,576      |\n",
      "| pred_head   | 430,920     |\n",
      "| proj_t      | 262,656     |\n",
      "| TOTAL       | 128,714,825 |\n",
      "torch.Size([4, 48, 192])\n",
      "torch.Size([4, 12, 256])\n",
      "torch.Size([4, 48, 840]) torch.Size([4, 48, 840])\n",
      "contrastive loss = 0.334650456905365\n"
     ]
    }
   ],
   "source": [
    "model = MAEModel(psg_encoder_name=\"vit_tiny\",\n",
    "                  text_encoder_name=\"google/flan-t5-base\").eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss_dict, _ = model.shared_step(batch, batch_idx=0)\n",
    "print(\"contrastive loss =\", loss_dict[\"loss\"].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce874c-e70f-48db-8fc0-92ecc3ff06c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (melp)",
   "language": "python",
   "name": "melp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
